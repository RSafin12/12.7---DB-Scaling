# 12.7-DB-Scaling

## Задание 1
1. активный master-сервер и пассивный репликационный slave-сервер;  
Из преимуществ можно выделить простоту реализации. Репликация сама по себе позволяет повысить отказоустойчивость.  
2. master-сервер и несколько slave-серверов;  
Это вариант уже лучше, т.к. позволяет выбирать решения. В частности на лекции был упомянут интересный подход, где помимо мастер-ноды есть несколько реплик, асинхронные и синхронные. Синхронная реплика в случае сбоя становится мастером, а асинхронная становится синхронной.  
3. активный сервер со специальным механизмом репликации DRBD  
Это также очень интересный кейс, DRBD часто называют "сетевой RAID". Этот инструмент можно использовать не только для БД, а в целом для любых данных. DRBD имеет гибкую настройку и часто используется для создания HA кластеров, что говорит о надежности инструмента. Если немного покопаться на сайте вендора Linbit, то можно найти еще и что-то вроде "оркестратора блочных устройств" - Linstor  
4. SAN-кластер.  
Насколько мне известно, такие решения используются, когда идет речь об обработке большого объема данных, на сегодняшний день чаще всего используют хранилища, работающие по iSCSI, и такое хранилище в ОС обнаруживается как блочное устройство. Это удобная технология, когда у вас есть огромное хранилище из которого можно выделять куски в виде сетевых дисков под разные нужды. И такие хранилища относительно легко масштабировать.  


## Задание 2 
![pic](https://github.com/RSafin12/12.7---DB-Scaling/blob/main/diagram.png)
0. Имеем исходные данные в виде БД с таблицами users, books, stores. Предполагаем, что возможности вертикального масштабирования даже не подходят. Есть мнение, что для MySQL пределом будет 8 CPU и 14 дисков, после сервер мощнее уже не даст прироста производительности.   

1. На первом этапе мы можем каждую таблицу(или группу таблиц) разнести по отдельным нодам, т.е. произвести вертикальный шардинг.   

2. В случае, если таблица огромная и содержит много столбцов, то сами столбцы(или группы столбцов) можно вынести в отдельные таблицы и также вынести на отдельные ноды(в данном контексте их иногда просто назвают шардами). Это горизонтальный шардинг, делается путем:  
- На нескольких серверах создается одна и та же таблица(только структура, без данных)  
- На уровне приложения выбирается условие, по которому будет происходить соединение.   
- Перед каждым обращением к таблице выбирается нужное соединение.  

Также отмечу, что горизонтальный шардинг часто применяется с репликацией, можно реплицировать шарды, записывая данные на мастер, а читая со слейвов.   
3. И если этого будет мало, то можно разделить таблицу на партиции по определенному условию, также разнеся на ноды. Есть разные принципы выбора условия, можно разделить на фиксированные диапазоны по u_id, например. 

